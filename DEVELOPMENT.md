# F1PA - Guide de d√©veloppement et d√©ploiement

Guide complet pour le d√©veloppement, les tests, le CI/CD et le d√©ploiement de F1PA.

---

## üìã Table des mati√®res

- [Installation](#-installation)
- [D√©veloppement local](#-d√©veloppement-local)
- [Tests & Qualit√©](#-tests--qualit√©)
- [CI/CD Pipeline](#-cicd-pipeline)
- [D√©ploiement](#-d√©ploiement)
- [Monitoring](#-monitoring)
- [Maintenance](#-maintenance)

---

## üîß Installation

### Pr√©requis

- Python 3.10+
- Docker & Docker Compose
- Git

### Configuration environnement local

```bash
# Cloner le projet
git clone https://github.com/Aurelien-L/F1PA.git
cd F1PA

# Cr√©er environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Installer d√©pendances
pip install --upgrade pip
pip install -r requirements.txt

# Installer outils de d√©veloppement
pip install pytest pytest-cov pytest-asyncio pylint
```

### D√©marrer les services

```bash
# Lancer tous les services Docker
docker compose up -d

# V√©rifier l'√©tat
docker compose ps

# Tester l'API
curl -u f1pa:f1pa http://localhost:8000/health
```

**Services disponibles** :
- API Documentation : http://localhost:8000/docs
- Streamlit UI : http://localhost:8501
- MLflow : http://localhost:5000
- Grafana : http://localhost:3000 (admin/admin)
- Prometheus : http://localhost:9090

---

## üíª D√©veloppement local

### Pipeline ETL

```bash
# Pipeline complet (Extract ‚Üí Transform ‚Üí Load)
python scripts/etl_pipeline.py --years 2023 2024 2025

# Pipeline sans Extract (donn√©es d√©j√† extraites)
python scripts/etl_pipeline.py --years 2023 2024 2025 --skip-extract

# V√©rification qualit√© uniquement
python scripts/etl_pipeline.py --verify-only

# Extraction drivers standalone
python scripts/extract_drivers.py --years 2023 2024 2025
```

### Machine Learning

```bash
# Entra√Æner le mod√®le
python ml/run_ml_pipeline.py

# G√©n√©rer rapport de drift
docker exec f1pa_api python scripts/generate_drift_report.py
```

### Docker - Commandes courantes

```bash
# Services
docker compose up -d              # D√©marrer tous les services
docker compose down               # Arr√™ter tous les services
docker compose restart            # Red√©marrer les services
docker compose logs -f            # Voir les logs en temps r√©el
docker compose logs -f api        # Logs d'un service sp√©cifique

# Build
docker compose build              # Builder toutes les images
docker compose build api          # Builder une image sp√©cifique
docker compose up -d --build      # Builder et d√©marrer

# Nettoyage
docker compose down -v            # Arr√™ter et supprimer les volumes
docker system prune -af           # Nettoyer tout (‚ö†Ô∏è ATTENTION)
```

### Astuces utiles

```bash
# Ex√©cuter commandes dans container
docker exec -it f1pa_api bash
docker exec f1pa_api python scripts/generate_drift_report.py

# PostgreSQL
docker exec -it f1pa_postgres psql -U f1pa -d f1pa_db

# Backup PostgreSQL
docker exec f1pa_postgres pg_dump -U f1pa f1pa_db > backup.sql

# Restore PostgreSQL
cat backup.sql | docker exec -i f1pa_postgres psql -U f1pa f1pa_db
```

---

## üß™ Tests & Qualit√©

### V√©rification code avec Pylint

```bash
# V√©rifier tous les modules
pylint --rcfile=pyproject.toml api/ ml/ etl/ monitoring/ streamlit/ tests/ scripts/

# V√©rifier un module sp√©cifique
pylint --rcfile=pyproject.toml api/

# V√©rifier un fichier sp√©cifique
pylint --rcfile=pyproject.toml api/main.py
```

**Score cible** : > 9.0/10

### Tests unitaires

```bash
# Lancer tous les tests (unit + integration)
pytest tests/ -v

# Lancer uniquement les tests unitaires (sans services Docker)
pytest tests/ -v -m "not integration"

# Lancer uniquement les tests d'int√©gration (n√©cessite docker compose up -d)
pytest tests/ -v -m "integration"

# Avec coverage
pytest tests/ -v --cov=. --cov-report=term-missing --cov-report=html

# Lancer un test sp√©cifique
pytest tests/test_api.py -v

# Lancer une fonction de test sp√©cifique
pytest tests/test_api.py::test_health_endpoint -v
```

**Tests disponibles** :
- **43 tests unitaires** (peuvent tourner sans services Docker ni donn√©es) :
  - 11 tests API (`test_api.py`)
  - 7 tests API √©tendus (`test_api_extended.py`)
  - 4 tests configuration (`test_config.py`)
  - 14 tests validation donn√©es (`test_data_validation.py`) - Nouveaux ! ‚ú®
  - 7 tests preprocessing (`test_preprocessing.py`)
- **11 tests d'int√©gration** (n√©cessitent `docker compose up -d`) :
  - 6 tests API compl√®te (`test_api_extended.py`)
  - 5 tests service ML (`test_ml_service.py`)
- **Total** : 54 tests, 100% de pass

**Note** : Les tests d'int√©gration sont automatiquement exclus du pipeline GitHub Actions pour garder le CI/CD simple et rapide.

**Tests de validation donn√©es** (`test_data_validation.py`) :
- Sch√©ma dataset ML (colonnes requises)
- Ranges vitesses F1 (20-380 km/h)
- Ranges lap times (50-1200s, d√©tection outliers > 300s)
- NaN limit√©s (< 1% target, < 10-20% features)
- Coh√©rence secteurs (somme ‚âà lap_duration)
- Coh√©rence m√©t√©o (temp√©rature, pression, humidit√©)
- Unicit√© laps (pas de duplicates)
- S√©quentialit√© num√©ros de tours

**Strat√©gie outliers** : L'ETL supprime les outliers par quantiles per-session (Q0.01-Q0.99, 1534 laps supprim√©s). Les tests d√©tectent les outliers extr√™mes restants (< 0.1%, typiquement sessions √† incidents). Random Forest est robuste √† ces cas rares.

### Pipeline CI/CD local

Simuler le pipeline GitHub Actions en local avant de push :

```bash
# 1. Lint
pylint --rcfile=pyproject.toml api/ ml/ etl/ monitoring/ streamlit/ tests/ scripts/

# 2. Tests (uniquement tests unitaires comme en CI)
pytest tests/ -v --cov -m "not integration"

# 3. Tests complets (unit + integration, n√©cessite docker compose)
docker compose up -d
pytest tests/ -v --cov  # Tous les tests

# 4. Build Docker
docker compose build

# 5. V√©rifier sant√©
docker compose ps
curl -u f1pa:f1pa http://localhost:8000/health
```

---

## üöÄ CI/CD Pipeline

### Architecture GitHub Actions

```
Push ‚Üí Lint ‚Üí Tests ‚Üí Build ‚Üí Deploy
       ‚Üì      ‚Üì       ‚Üì
    pylint  pytest  docker
           29 unit   images
           tests
```

### Workflows automatiques

**`.github/workflows/ci.yml`** - Pipeline principal

D√©clench√© sur :
- Push sur `main`, `dev`, `feat-*`
- Pull requests vers `main`, `dev`

√âtapes :
1. **Lint** : V√©rification code avec pylint
2. **Tests** : Ex√©cution pytest + coverage (29 tests unitaires, PostgreSQL service uniquement)
   - Tests d'int√©gration exclus pour garder le CI/CD simple et rapide
3. **Build** : Construction images Docker (uniquement sur main/dev)

**`.github/workflows/release.yml`** - Workflow de release

D√©clench√© sur :
- Tags `v*.*.*`

Cr√©e automatiquement une release GitHub avec les images Docker versionn√©es.

### Cr√©er une release

```bash
# Cr√©er et pusher un tag
git tag -a v1.0.0 -m "Release v1.0.0"
git push origin v1.0.0

# Le workflow release.yml se d√©clenche automatiquement
```

### Strat√©gie de d√©ploiement

**D√©ploiement actuel** :
- ‚úÖ **Build Docker automatique** : Images construites automatiquement sur push `main`/`dev`
- ‚è∏Ô∏è **D√©ploiement manuel** : Via script `scripts/deploy.sh`
- üí° **Choix volontaire** : √âviter d√©ploiements accidentels pendant le d√©veloppement

**Avantages d√©ploiement manuel** :
- Contr√¥le total sur le timing du d√©ploiement
- Validation manuelle avant mise en production
- √âvite les d√©ploiements non test√©s en environnement dev

**Migration vers d√©ploiement automatique** (pour production) :

1. D√©commenter la section deploy dans `.github/workflows/ci.yml` (lignes 127-142)
2. Configurer les secrets GitHub :
   ```bash
   # Settings ‚Üí Secrets ‚Üí Actions ‚Üí New repository secret
   SSH_PRIVATE_KEY: <cl√© SSH serveur de production>
   SERVER_HOST: <IP ou domaine du serveur>
   SERVER_USER: <utilisateur SSH>
   ```
3. Le d√©ploiement se d√©clenchera automatiquement apr√®s build r√©ussi sur `main`

**Script de d√©ploiement manuel** :

```bash
# D√©ployer sur serveur distant
./scripts/deploy.sh

# Avec variables d'environnement
SERVER_HOST=prod.example.com SERVER_USER=deployer ./scripts/deploy.sh
```

### Activer le d√©ploiement automatique

Pour activer le d√©ploiement automatique vers la production, d√©commenter la section `deploy` dans `.github/workflows/ci.yml` et configurer les secrets GitHub :

**Secrets √† configurer** (Settings ‚Üí Secrets ‚Üí Actions) :
- `SSH_PRIVATE_KEY` : Cl√© SSH priv√©e pour le serveur
- `SERVER_HOST` : IP ou domaine du serveur
- `SERVER_USER` : Utilisateur SSH

---

## üì¶ D√©ploiement

### D√©ploiement automatis√© (script interactif)

```bash
bash scripts/deploy.sh
```

Options :
1. **Local development** : Build + d√©marrage services
2. **Production** : D√©ploiement via SSH sur serveur distant

### D√©ploiement manuel en production

#### 1. Pr√©paration serveur

```bash
# Connexion SSH
ssh user@server

# Installation Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Installation Docker Compose
sudo apt-get update
sudo apt-get install docker-compose-plugin

# V√©rification
docker --version
docker compose version
```

**Configuration minimale serveur** :
- 4GB RAM
- 20GB disque
- Ports : 5000, 5432, 8000, 8501, 3000, 9090

#### 2. Cloner et configurer

```bash
# Cloner le repository
git clone https://github.com/Aurelien-L/F1PA.git
cd F1PA

# Checkout version sp√©cifique (optionnel)
git checkout v1.0.0

# Configuration (optionnel)
cp .env.example .env
nano .env
```

**Variables d'environnement importantes** :
```bash
API_USERNAME=f1pa
API_PASSWORD=YOUR_SECURE_PASSWORD
POSTGRES_PASSWORD=YOUR_SECURE_PASSWORD
GF_SECURITY_ADMIN_PASSWORD=YOUR_SECURE_PASSWORD
```

#### 3. Lancement

```bash
# Build des images
docker compose build

# Lancement en mode d√©tach√©
docker compose up -d

# V√©rification
docker compose ps
docker compose logs -f
```

#### 4. V√©rification sant√©

```bash
# Health check API
curl -u f1pa:f1pa http://localhost:8000/health

# Test pr√©diction
curl -u f1pa:f1pa -X POST http://localhost:8000/predict/lap \
  -H "Content-Type: application/json" \
  -d '{
    "features": {
      "driver_number": 1,
      "circuit_key": 7,
      "st_speed": 310,
      "i1_speed": 295,
      "i2_speed": 285,
      "temp": 25,
      "rhum": 60,
      "pres": 1013,
      "lap_number": 10,
      "year": 2024,
      "circuit_avg_laptime": 85.5,
      "driver_avg_laptime": 84.2,
      "driver_perf_score": 0.85
    }
  }'
```

### Mise √† jour production

#### Rolling update (sans downtime)

```bash
# Pull derni√®res modifications
git pull origin main

# Rebuild seulement ce qui a chang√©
docker compose build

# Restart avec rolling update
docker compose up -d --no-deps --build api
docker compose up -d --no-deps --build streamlit

# V√©rification
docker compose ps
```

#### Update complet

```bash
# Stop tous les services
docker compose down

# Pull + rebuild
git pull origin main
docker compose build

# Red√©marrage
docker compose up -d

# Clean des anciennes images
docker image prune -f
```

---

## üìä Monitoring

### M√©triques Prometheus

```bash
# V√©rifier les targets
curl http://localhost:9090/api/v1/targets | python -m json.tool

# Query m√©triques
curl "http://localhost:9090/api/v1/query?query=f1pa_predictions_total"
```

### Grafana Dashboards

1. Acc√©der √† http://localhost:3000
2. Login : admin / admin
3. Dashboard : F1PA ‚Üí F1PA ML Model Monitoring

**Panels disponibles** :
- Prediction Requests/sec
- Prediction Latency (p95)
- Model Status
- Error Rate
- Database/MLflow Connection Status

### Evidently - Drift detection

```bash
# G√©n√©rer rapport de drift
docker exec f1pa_api python scripts/generate_drift_report.py

# Rapport HTML g√©n√©r√© dans:
# monitoring/evidently/reports/test_data_drift.html
```

### Logs

```bash
# Logs temps r√©el
docker compose logs -f

# Logs sp√©cifiques
docker compose logs -f api
docker compose logs -f streamlit

# Logs avec timestamp
docker compose logs -f --timestamps

# Derni√®res 100 lignes
docker compose logs --tail=100 api
```

---

## üõ†Ô∏è Maintenance

### Troubleshooting

#### Service ne d√©marre pas

```bash
# V√©rifier les logs
docker compose logs service_name

# V√©rifier l'√©tat
docker compose ps

# Restart service sp√©cifique
docker compose restart service_name
```

#### Probl√®me de connexion base de donn√©es

```bash
# V√©rifier que PostgreSQL est UP
docker compose ps postgres

# Tester la connexion
docker exec -it f1pa_postgres psql -U f1pa -d f1pa_db -c "SELECT 1;"

# Recr√©er la base (‚ö†Ô∏è perte de donn√©es)
docker compose down -v
docker compose up -d postgres
```

#### Manque d'espace disque

```bash
# Nettoyer les images inutilis√©es
docker system prune -a

# Nettoyer les volumes (‚ö†Ô∏è perte de donn√©es)
docker volume prune

# V√©rifier l'espace
docker system df
```

#### Performance d√©grad√©e

```bash
# V√©rifier ressources
docker stats

# Limiter ressources dans docker-compose.yml
services:
  api:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
```

### Backup & Restore

#### Backup base de donn√©es

```bash
# Backup manuel
docker exec f1pa_postgres pg_dump -U f1pa f1pa_db > backup_$(date +%Y%m%d).sql

# Backup automatique (cron)
0 2 * * * docker exec f1pa_postgres pg_dump -U f1pa f1pa_db > /backups/f1pa_$(date +\%Y\%m\%d).sql
```

#### Restore

```bash
# Restore depuis backup
docker exec -i f1pa_postgres psql -U f1pa -d f1pa_db < backup_20250129.sql
```

#### Backup volumes Docker

```bash
# Backup MLflow artifacts
tar -czf mlartifacts_backup.tar.gz mlartifacts/

# Backup Grafana data
docker run --rm -v f1pa_grafana_data:/data -v $(pwd):/backup alpine tar -czf /backup/grafana_backup.tar.gz -C /data .

# Restore
tar -xzf mlartifacts_backup.tar.gz
docker run --rm -v f1pa_grafana_data:/data -v $(pwd):/backup alpine tar -xzf /backup/grafana_backup.tar.gz -C /data
```

### Nettoyage cache Python

```bash
# Nettoyer __pycache__
find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null
find . -type f -name "*.pyc" -delete
find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null
rm -rf htmlcov/ .coverage
```

---

## üìö Ressources

- [README principal](README.md) - Vue d'ensemble du projet
- [Scripts README](scripts/README.md) - Documentation scripts utilitaires
- [Monitoring README](monitoring/README.md) - Guide monitoring d√©taill√©
- [RGPD](RGPD.md) - Conformit√© RGPD
- [API Documentation](http://localhost:8000/docs) - Swagger UI


