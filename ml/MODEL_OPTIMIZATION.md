# Optimisation du Mod√®le ML - F1PA

Documentation d√©taill√©e du processus d'optimisation du mod√®le Random Forest pour la pr√©diction des temps au tour.

---

## üéØ Objectif

D√©velopper un mod√®le Random Forest performant tout en respectant les contraintes de production :
- Taille mod√®le < 500 MB (pour upload MLflow)
- Temps de chargement API < 5s
- Performance pr√©dictive optimale (MAE, R¬≤)

---

## üìä Parcours d'Optimisation

### D√©fi Initial

**Probl√®me** : Mod√®le Random Forest trop volumineux (1.5 GB) causant des √©checs d'upload vers MLflow.

### It√©rations

| Version | Probl√®me | Solution appliqu√©e | R√©sultat |
|---------|----------|-------------------|----------|
| **v0** (baseline) | `max_depth=None` ‚Üí 1.5 GB, crash MLflow | - | ‚ùå Bloquant production |
| **v1** | Profondeur limit√©e mais toujours lourd | `max_depth=[15,20]` au lieu de `[15,None]` | 674 MB, ‚ö†Ô∏è encore lourd |
| **v2** | Besoin d'un mod√®le plus l√©ger | `n_estimators=[150,200]` au lieu de `[200,300]` | 449 MB, ‚ö†Ô∏è acceptable |
| **v3** | Coh√©rence train/inference + optimisation | lap_progress circuit-based + `n_estimators=150` | 351 MB, MAE 1.08s, R¬≤ 0.77 |
| **v6** (final) | Redondance feature driver_avg_laptime | Suppression driver_avg_laptime (14 features) | ‚úÖ **335 MB** (-78%), R¬≤ **0.79** |

---

## üìà R√©sultats Finaux

### Gains Mesur√©s

- **R√©duction taille** : 1.5 GB ‚Üí 335 MB (-78%)
- **Am√©lioration performance** : R¬≤ 0.77 ‚Üí 0.79 (+2.6%, meilleure g√©n√©ralisation)
- **R√©duction features** : 15 ‚Üí 14 (suppression redondance driver_avg_laptime)
- **Temps de chargement** : 19s ‚Üí ~3s dans l'API (-84%)

### M√©triques du Mod√®le v6

- **MAE** : 1.08s (test)
- **R¬≤** : 0.79 (test)
- **RMSE** : 11.56s (test)
- **MAPE** : 0.90%
- **Taille** : 335 MB
- **Features** : 14

---

## üîç Apprentissages Cl√©s

### 1. Profondeur des Arbres

**Constat** : Profondeur illimit√©e (`max_depth=None`) cr√©e un overfitting massif avec 300 arbres.

**Solution** : GridSearch a s√©lectionn√© `max_depth=20` comme optimal (√©quilibre pr√©cision/g√©n√©ralisation).

### 2. Nombre d'Estimateurs

**Constat** : 300 arbres = mod√®le trop lourd sans gain significatif de performance.

**Solution** : R√©duire `n_estimators` √† 150 offre le meilleur compromis taille/performance.

### 3. Coh√©rence Train/Inference

**Probl√®me initial** : Utilisation d'un `max_lap=70` fixe pour tous les circuits (Monaco=78 laps, Spa=44 laps).

**Solution impl√©ment√©e** : Calcul dynamique bas√© sur le max_lap typique du circuit
- Calcul du **max_lap typique** par circuit (moyenne des max_laps historiques)
- **Training** : `lap_progress = lap_number / avg(max_lap) par circuit`
- **Inference** : M√™me logique via requ√™te DB avec cache
- Requ√™te : `SELECT AVG(MAX(lap_number)) FROM fact_laps WHERE circuit_key = ? GROUP BY session_key`

**R√©sultat** : Coh√©rence training/inference pour pr√©dictions hypoth√©tiques.

### 4. Redondance des Features

**Constat** : `driver_avg_laptime` et `driver_perf_score` sont redondants.
- `driver_perf_score` = `driver_avg_laptime` - `circuit_avg_laptime`
- Les deux features encodent la m√™me information relative

**Solution** : Suppression de `driver_avg_laptime`, conservation de `driver_perf_score` uniquement.

**Impact** :
- R√©duction overfitting ‚Üí +2.6% R¬≤ (0.77 ‚Üí 0.79)
- Mod√®le plus l√©ger (351 MB ‚Üí 335 MB)
- Pr√©dictions plus logiques (Verstappen > Stroll)

---

## ‚öôÔ∏è Configuration de Production

### Hyperparam√®tres GridSearch

```python
# ml/config.py - Param√®tres GridSearch Random Forest
'n_estimators': [150, 200],      # Mod√®le plus l√©ger (cible ~450 MB)
'max_depth': [15, 20],            # √âvite l'overfitting (√©tait [15, None])
'min_samples_leaf': [1, 2],       # Param√®tres standard
'min_samples_split': [2, 5],      # Param√®tres standard
'max_features': [0.7, 0.9],       # Feature sampling
```

### Param√®tres S√©lectionn√©s (v6)

```python
{
    'n_estimators': 150,
    'max_depth': 20,
    'min_samples_leaf': 1,
    'min_samples_split': 2,
    'max_features': 0.7
}
```

---

## üì¶ Features Finales (14 total)

### Contexte (4)
- `year` : Ann√©e de la session
- `circuit_key` : Identifiant du circuit
- `driver_number` : Num√©ro du pilote
- `lap_number` : Num√©ro du tour dans la session

### Vitesses (3)
- `st_speed` : Vitesse au speed trap (km/h)
- `i1_speed` : Vitesse interm√©diaire 1 (km/h)
- `i2_speed` : Vitesse interm√©diaire 2 (km/h)

### M√©t√©o (3)
- `temp` : Temp√©rature (¬∞C)
- `rhum` : Humidit√© relative (%)
- `pres` : Pression atmosph√©rique (hPa)

### Performance (4)
- `circuit_avg_laptime` : Temps moyen du circuit (s)
- `avg_speed` : Vitesse moyenne calcul√©e (km/h)
- `lap_progress` : Progression dans la session (0-1)
- `driver_perf_score` : Score de performance pilote (n√©gatif = plus rapide)

**Feature supprim√©e** : `driver_avg_laptime` (redondance avec driver_perf_score)

---

## üîÑ Processus de R√©entra√Ænement

### Quand r√©entra√Æner ?

1. **Nouveaux donn√©es disponibles** : Nouvelle saison F1
2. **Drift d√©tect√©** : Rapport Evidently signale un drift significatif
3. **Performance d√©grad√©e** : MAE > 1.5s sur donn√©es r√©centes
4. **Changements r√©glementaires** : Nouveaux r√®glements F1 impactant les performances

### Commande

```bash
python ml/run_ml_pipeline.py
```

### Validation

V√©rifier que le nouveau mod√®le :
- MAE < 1.2s
- R¬≤ > 0.75
- Taille < 500 MB
- Pr√©dictions logiques (top pilotes > pilotes moyens)

---

## üìö R√©f√©rences

- MLflow Run ID v6 : `3261c2b8d2f440848ca459cd35e67e14`
- Rapport d'entra√Ænement : `reports/random_forest_gridsearch/training_report.json`
- Tracking MLflow : http://localhost:5000
