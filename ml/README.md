# F1PA - Machine Learning Pipeline

**Pr√©diction des Temps au Tour en Formule 1**

---

## üìã Table des Mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture](#architecture)
3. [Installation & Pr√©requis](#installation--pr√©requis)
4. [Ex√©cution Rapide](#ex√©cution-rapide)
5. [Dataset](#dataset)
6. [Feature Engineering](#feature-engineering)
7. [Mod√®les & Strat√©gie](#mod√®les--strat√©gie)
8. [R√©sultats](#r√©sultats)
9. [Utilisation des Mod√®les](#utilisation-des-mod√®les)
10. [MLflow](#mlflow)
11. [Am√©liorations Futures](#am√©liorations-futures)

---

## Vue d'ensemble

Le projet F1PA impl√©mente un syst√®me de pr√©diction des temps au tour en Formule 1 bas√© sur des donn√©es publiques (2023-2025). L'objectif est de pr√©dire le `lap_duration` (dur√©e du tour en secondes) en utilisant uniquement des donn√©es accessibles publiquement.

### Objectif

Pr√©dire le temps au tour d'un pilote en fonction de:
- **Donn√©es sportives**: Vitesses (st_speed, i1_speed, i2_speed), temps secteurs
- **Donn√©es m√©t√©o**: Temp√©rature, humidit√©, pression, vent, pr√©cipitations
- **Contexte**: Circuit, pilote, progression dans la course

### Contraintes

- ‚úÖ Donn√©es publiques uniquement (pas de t√©l√©m√©trie voiture)
- ‚úÖ Split temporel (2023-2024 train, 2025 test)
- ‚úÖ R√©gularisation anti-overfitting
- ‚úÖ Tracking MLflow professionnel

---

## Architecture

```
ml/
‚îú‚îÄ‚îÄ config.py              # Configuration (chemins, hyperparam√®tres)
‚îú‚îÄ‚îÄ preprocessing.py       # Feature engineering et pr√©paration des donn√©es
‚îú‚îÄ‚îÄ train.py              # Pipeline d'entra√Ænement complet
‚îú‚îÄ‚îÄ load_model_simple.py  # Chargement dynamique des mod√®les
‚îú‚îÄ‚îÄ run_ml_pipeline.py    # Script d'ex√©cution tout-en-un (RECOMMAND√â)
‚îî‚îÄ‚îÄ README.md            # Ce fichier
```

### Flux de Travail

```
Donn√©es brutes (CSV)
    ‚Üì
[preprocessing.py] ‚Üí Feature engineering (17 features)
    ‚Üì
[train.py] ‚Üí Entra√Ænement (XGBoost + Random Forest)
    ‚Üì
[MLflow] ‚Üí Tracking (m√©triques, artifacts)
    ‚Üì
[load_model_simple.py] ‚Üí Chargement pour inf√©rence
```

---

## Installation & Pr√©requis

### 1. Environnement Python

```bash
# Cr√©er environnement virtuel
python -m venv .venv

# Activer (Windows)
.venv\Scripts\activate

# Activer (Linux/Mac)
source .venv/bin/activate

# Installer d√©pendances
pip install -r requirements.txt
```

### 2. MLflow avec Docker

```bash
# D√©marrer PostgreSQL + MLflow
docker-compose up -d

# V√©rifier
curl http://localhost:5000/health
# Expected: OK
```

### 3. Donn√©es

Le dataset doit √™tre pr√©sent dans:
```
data/processed/dataset_ml_lap_level_2023_2024_2025.csv
```

---

## Ex√©cution Rapide

### Option 1: Script Tout-en-Un (RECOMMAND√â)

```bash
# Ex√©cute le pipeline complet
python ml/run_ml_pipeline.py
```

Ce script:
1. V√©rifie les pr√©requis (dataset, MLflow)
2. Lance l'entra√Ænement complet
3. Affiche les r√©sultats
4. Guide pour charger les mod√®les

### Option 2: √âtape par √âtape

```bash
# 1. Entra√Æner tous les mod√®les
python -m ml.train

# 2. Voir les mod√®les disponibles
python -m ml.load_model_simple

# 3. Acc√©der √† l'interface MLflow
# http://localhost:5000
```

---

## Dataset

### Caract√©ristiques

| Attribut | Valeur |
|----------|--------|
| **P√©riode** | 2023-2025 (3 saisons) |
| **Samples totaux** | 71,645 tours |
| **Train** | 47,266 tours (2023-2024) - 66% |
| **Test** | 24,379 tours (2025) - 34% |
| **Split** | Temporel (√©vite data leakage) |
| **Features** | 17 (apr√®s feature selection) |

### Variables Cl√©s

**Sportives**:
- `st_speed`, `i1_speed`, `i2_speed`: Vitesses mesur√©es
- `duration_sector_1/2/3`: Temps par secteur
- `lap_number`: Position dans la course

**M√©t√©o**:
- `temp`: Temp√©rature (¬∞C)
- `pres`: Pression atmosph√©rique (hPa)
- `rhum`: Humidit√© relative (%)
- `wspd`: Vitesse du vent (m/s)

**Contexte**:
- `circuit_key`: Identifiant circuit
- `driver_number`: Num√©ro pilote
- `year`: Saison

---

## Feature Engineering

### 1. Imputation des Valeurs Manquantes

**Strat√©gie**: Imputation group√©e (circuit, pilote)
- Vitesses et temps secteurs ‚Üí Moyenne par (circuit, pilote)
- M√©t√©o ‚Üí Forward fill + m√©diane globale

```python
# Exemple
df['st_speed'] = df.groupby(['circuit_key', 'driver_number'])['st_speed'].transform(
    lambda x: x.fillna(x.mean())
)
```

### 2. Features D√©riv√©es (6)

| Feature | Formule | Utilit√© |
|---------|---------|---------|
| `avg_speed` | Moyenne(st, i1, i2) | Vitesse moyenne globale |
| `total_sector_time` | Œ£(sector_1,2,3) | Temps tour estim√© |
| `sector_1_ratio` | sector_1 / total | Style pilotage (freinage) |
| `sector_2_ratio` | sector_2 / total | Style pilotage (virage) |
| `weather_severity` | wspd √ó prcp | Difficult√© m√©t√©o |
| `lap_progress` | lap / max_lap | D√©gradation pneus |

### 3. Target Encoding (3 features)

Encode les variables cat√©gorielles par la moyenne du target:

```python
circuit_avg_laptime = mean(lap_duration | circuit)
driver_avg_laptime = mean(lap_duration | driver)
year_avg_laptime = mean(lap_duration | year)
```

**Avantage**: Capture l'effet sp√©cifique de chaque circuit/pilote sur le temps au tour.

### 4. Feature Selection

**24 features initiales ‚Üí 17 features finales**

Supprim√©es (importance < 0.001):
- `year_avg_laptime`, `prcp`, `wspd`, `cldc`, `wdir`
- `weather_severity`, `driver_avg_laptime`

**Top 10 Features par Importance**:

| Rang | Feature | Importance | Type |
|------|---------|------------|------|
| 1 | lap_number | 22.9% | Progression |
| 2 | lap_progress | 17.9% | D√©gradation |
| 3 | temp | 14.5% | M√©t√©o |
| 4 | pres | 6.0% | M√©t√©o |
| 5 | sector_1_ratio | 5.0% | Style |
| 6 | sector_2_ratio | 4.9% | Style |
| 7 | duration_sector_3 | 4.7% | Performance |
| 8 | rhum | 4.0% | M√©t√©o |
| 9 | duration_sector_1 | 3.4% | Performance |
| 10 | circuit_avg_laptime | 3.3% | Contexte |

---

## Mod√®les & Strat√©gie

### Mod√®les Test√©s

4 mod√®les entra√Æn√©s √† chaque run:

1. **XGBoost Baseline**: Configuration par d√©faut
2. **XGBoost GridSearch V2.1**: Hyperparam√®tres optimis√©s + r√©gularisation ‚≠ê
3. **Random Forest Baseline**: Configuration par d√©faut
4. **Random Forest GridSearch**: Hyperparam√®tres optimis√©s

### XGBoost GridSearch V2.1 (RECOMMAND√â)

**Hyperparam√®tres**:

```python
{
    'n_estimators': 150,        # Nombre d'arbres
    'max_depth': 5,             # Profondeur max (r√©gularisation)
    'learning_rate': 0.03,      # Taux d'apprentissage faible
    'min_child_weight': 5,      # R√©gularisation (split minimum)
    'gamma': 0.05,              # R√©gularisation (perte minimum)
    'subsample': 0.75,          # 75% des donn√©es par arbre
    'colsample_bytree': 0.75,   # 75% des features par arbre
    'reg_alpha': 0.05,          # L1 regularization
    'reg_lambda': 0.5           # L2 regularization
}
```

**Strat√©gie Anti-Overfitting**:
1. R√©duction de la profondeur (max_depth: 5)
2. Learning rate faible (0.03)
3. R√©gularisation L1/L2
4. Subsampling (donn√©es + features)
5. Early stopping (via cross-validation)

### √âvolution des Versions

| Version | Strategy | Test MAE | Test R¬≤ | Overfitting | Note |
|---------|----------|----------|---------|-------------|------|
| **V1** | Baseline | **0.96s** ‚úÖ | 0.675 | 11.76 ‚ùå | Performance max |
| **V2.1** | R√©gularis√©e | 1.31s | **0.686** ‚úÖ | **3.44** ‚úÖ | **Production** ‚≠ê |

**Trade-off V2.1**:
- Sacrifie 0.35s de MAE
- Gagne +30% en R¬≤
- Divise l'overfitting par 3
- ‚Üí **Meilleure g√©n√©ralisation sur donn√©es futures**

---

## R√©sultats

### M√©triques Finales (XGBoost V2.1)

**Test Set (2025)**:
- **MAE**: 1.31s (erreur moyenne)
- **RMSE**: 7.97s (p√©nalise erreurs extr√™mes)
- **R¬≤**: 0.686 (68.6% variance expliqu√©e)
- **MAPE**: 114.8% (sensible aux valeurs proches de 0)
- **Overfitting Ratio**: 3.44 (Train MAE: 0.38s vs Test MAE: 1.31s)

**Cross-Validation (2023-2024)**:
- **CV MAE**: 0.55s ¬± 0.07s
- **CV R¬≤**: 0.912 ¬± 0.069

### Analyse des R√©sultats

**‚úÖ Points Forts**:
- Bonne g√©n√©ralisation (overfitting ma√Ætris√©)
- R¬≤ 0.686 excellent avec donn√©es publiques uniquement
- Pr√©diction √† ¬±1.3s du temps r√©el
- Robuste aux changements de saison (concept drift g√©r√©)

**‚ö†Ô∏è Limitations**:
- Erreur plus √©lev√©e que les √©curies F1 (MAE ~0.1-0.2s avec t√©l√©m√©trie)
- Gap CV-Test (0.912 ‚Üí 0.686) d√ª aux √©volutions 2025
- MAPE √©lev√© (sensible aux tours lents: SC, VSC)

**üîç Concept Drift**:
- Score: 0.23 (√©cart CV ‚Üí Test)
- Causes: R√©glementations 2025, √©volution pilotes

---

## Utilisation des Mod√®les

### 1. Charger le Meilleur Mod√®le (Automatique)

```python
from ml.load_model_simple import load_model_from_mlflow

# Strat√©gie "robust" (RECOMMAND√â pour production)
model, info = load_model_from_mlflow(strategy='robust', model_family='xgboost')

print(f"Run ID: {info['run_id']}")
print(f"Test MAE: {info['test_mae']:.3f}s")
print(f"Overfitting: {info['overfitting_ratio']:.2f}")

# Pr√©diction
import pandas as pd
X_new = pd.DataFrame([...])  # Vos features
predictions = model.predict(X_new)
```

### 2. Strat√©gies de Chargement

**Strat√©gie "robust"** (d√©faut):
- S√©lectionne le mod√®le avec le meilleur compromis robustesse/performance
- Crit√®res: Overfitting < 5.0, MAE < 1.5s
- Tri par overfitting croissant

**Strat√©gie "mae"**:
- S√©lectionne le mod√®le avec le meilleur Test MAE absolu
- Ignore l'overfitting

```python
# Performance absolue
model, info = load_model_from_mlflow(strategy='mae', model_family='xgboost')

# Random Forest
model, info = load_model_from_mlflow(strategy='robust', model_family='random_forest')
```

### 3. Chargement d'un Run Sp√©cifique

```python
# Pour reproductibilit√© exacte
run_id = "c8dfcd905f194ae598e62cb5505eb355"
model, info = load_model_from_mlflow(run_id=run_id)
```

### 4. Fallback Local (Sans MLflow)

```python
from ml.load_model_simple import load_model_local

# Si MLflow indisponible
model, info = load_model_local(model_family='xgboost')
# Charge depuis models/xgboost_gridsearch_model.pkl
```

### 5. Afficher les Mod√®les Disponibles

```python
from ml.load_model_simple import show_models_info

show_models_info()
# Affiche tous les runs GridSearch avec m√©triques
```

---

## MLflow

### Configuration

MLflow est configur√© avec Docker pour:
- **Backend store**: SQLite (`./mlflow_db/mlflow.db`) - Persistant
- **Artifact store**: File system (`./mlartifacts/`) - Persistant
- **Tracking URI**: http://localhost:5000

### Artifacts Logg√©s

Pour chaque run:
- `model/model_artifact.pkl`: Mod√®le s√©rialis√©
- `feature_importance.csv`: Importance des features
- `feature_importance.png`: Graphique importance
- `predictions_vs_actual.png`: Scatter plot pr√©dictions
- `residuals_distribution.png`: Distribution des r√©sidus
- `training_report.json`: Rapport complet (m√©triques, params)
- `gridsearch_results.csv`: R√©sultats GridSearch (si applicable)

### M√©triques Track√©es

- `test_mae`, `test_rmse`, `test_r2`, `test_mape`: M√©triques test
- `train_mae`, `train_rmse`, `train_r2`: M√©triques train
- `cv_mae`, `cv_r2`: Cross-validation (moyenne ¬± std)
- `overfitting_ratio`: train_mae / test_mae
- `concept_drift_score`: |cv_r2 - test_r2|

### Persistance

‚úÖ **Les experiments et runs persistent** apr√®s red√©marrage des containers gr√¢ce au volume Docker `./mlflow_db/`.

**V√©rification**:
```bash
# Red√©marrer MLflow
docker-compose restart mlflow

# Les runs sont toujours l√†
python -m ml.load_model_simple
```

### Interface Web

```bash
# Acc√©der √† l'interface
open http://localhost:5000

# Voir les runs
# ‚Üí Experiments ‚Üí F1PA_LapTime_Prediction

# Voir les artifacts d'un run
# ‚Üí Run ‚Üí Artifacts tab
```

---

## Am√©liorations Futures

### Court Terme (Impl√©mentables)

1. **Donn√©es Suppl√©mentaires**
   - SafetyCar/VSC (interruptions)
   - Position en grille (qualification)
   - Compound pneus (Soft/Medium/Hard)
   - Statut pneus (√¢ge, √©tat)

2. **Feature Engineering Avanc√©**
   - √âcart inter-quartile secteurs (outliers)
   - Moving average 5 derniers tours (tendance)
   - Features cycliques (lap_number ‚Üí sin/cos)
   - Interaction features (temp √ó rhum, wind √ó rain)

3. **Ensembling**
   - Stacking XGBoost + Random Forest + Linear
   - Blending predictions avec pond√©ration optimale
   - Voting classifier

4. **Optimisation Hyperparam√®tres**
   - Bayesian optimization (Optuna, Hyperopt)
   - Early stopping plus agressif
   - Augmenter nombre CV folds (5 ‚Üí 10)

### Long Terme (N√©cessite Donn√©es Priv√©es)

1. **T√©l√©m√©trie Voiture**
   - Setup a√©rodynamique (downforce)
   - Pression pneus, temp√©rature freins
   - Strat√©gie carburant
   - DRS activation

2. **Deep Learning**
   - LSTM pour s√©ries temporelles (tour par tour)
   - Transformer avec attention mechanism
   - Autoencoders pour feature extraction

3. **Transfer Learning**
   - Pr√©-entra√Æner sur F2/F3/Formula E
   - Fine-tuner sur F1
   - Domain adaptation

---

## FAQ

### Q: Pourquoi MAE 1.31s au lieu de < 0.5s?

**R**: Avec donn√©es publiques uniquement, impossible d'atteindre MAE < 0.5s. Les √©curies F1 (avec t√©l√©m√©trie compl√®te) atteignent MAE ~0.1-0.2s. Notre 1.31s est excellent dans ce contexte.

### Q: Pourquoi choisir V2.1 plut√¥t que V1 (meilleur MAE)?

**R**: V1 a un overfitting de 11.76 (m√©morise les donn√©es). V2.1 a overfitting de 3.44 (g√©n√©ralise mieux). En production, on pr√©f√®re un mod√®le qui g√©n√©ralise sur donn√©es futures.

### Q: Comment interpr√©ter l'overfitting ratio?

**R**:
- **1.0-1.5**: Excellent (mod√®le g√©n√©ralise parfaitement)
- **1.5-3.0**: Bon (l√©g√®re m√©morisation)
- **3.0-5.0**: Acceptable (m√©morisation mod√©r√©e) ‚Üê V2.1 ici
- **> 5.0**: Probl√©matique (forte m√©morisation) ‚Üê V1 ici

### Q: Les runs MLflow sont-ils sauvegard√©s?

**R**: Oui, gr√¢ce au volume Docker `./mlflow_db/`, tous les runs persistent apr√®s red√©marrage. Vous pouvez arr√™ter/red√©marrer les containers sans perdre l'historique.

### Q: Puis-je entra√Æner sans MLflow?

**R**: Oui, mais non recommand√©. Si MLflow est indisponible:
1. Les mod√®les sont quand m√™me sauvegard√©s dans `models/`
2. Utilisez `load_model_local()` pour charger
3. Mais vous perdez le tracking, les artifacts, et la tra√ßabilit√©

### Q: Comment sauvegarder mes mod√®les?

**R**:
```bash
# Backup complet (DB + artifacts + models locaux)
tar -czf f1pa_models_backup_$(date +%Y%m%d).tar.gz mlflow_db/ mlartifacts/ models/

# Restaurer
tar -xzf f1pa_models_backup_YYYYMMDD.tar.gz
```

---

## R√©sum√© Ex√©cutif

**F1PA ML Pipeline** est un syst√®me complet de pr√©diction des temps au tour en Formule 1:

‚úÖ **Dataset**: 71,645 tours (2023-2025), split temporel
‚úÖ **Features**: 17 features (apr√®s engineering et selection)
‚úÖ **Mod√®le**: XGBoost V2.1 r√©gularis√© (MAE 1.31s, R¬≤ 0.686, Overfitting 3.44)
‚úÖ **Tracking**: MLflow avec persistance (http://localhost:5000)
‚úÖ **Chargement**: Dynamique sans run IDs pr√©d√©finis
‚úÖ **Documentation**: Compl√®te avec guides d'utilisation
