<p align="center">
  <img src="img/f1pa_banner.png" alt="F1PA Banner" width="800"/>
</p>

<h1 align="center">F1PA - Formula 1 Predictive Assistant</h1>

<p align="center">
  <strong>Pipeline ETL complet + ModÃ¨le ML pour prÃ©dire les temps au tour en Formule 1</strong><br>
  Projet d'IA appliquÃ©e au sport automobile
</p>

<p align="center">
  <a href="#-vue-densemble">Vue d'ensemble</a> â€¢
  <a href="#-dÃ©marrage-rapide">DÃ©marrage rapide</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-monitoring--mlops">Monitoring</a> â€¢
  <a href="#-documentation">Documentation</a>
</p>

---

## ðŸ“Š Vue d'ensemble

**Objectif** : PrÃ©dire le temps au tour (`lap_duration`) d'un pilote, basÃ© sur sa performance historique et les conditions.

**DonnÃ©es** :
- 71,645 tours de piste (2023-2025)
- 24 circuits Ã— 32 pilotes
- Features : vitesses, mÃ©tÃ©o, contexte circuit/pilote
- Sources : OpenF1 API, Wikipedia, Meteostat

**Stack** :
- **Backend** : Python 3.10+, PostgreSQL 15, FastAPI
- **ML** : scikit-learn, XGBoost, MLflow
- **Monitoring** : Prometheus, Grafana, Evidently
- **MLOps** : Docker, GitHub Actions (CI/CD)

---

## ðŸš€ DÃ©marrage rapide

### PrÃ©requis

```bash
# Cloner le projet
git clone https://github.com/<user>/F1PA.git
cd F1PA

# CrÃ©er environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Installer dÃ©pendances
pip install -r requirements.txt
```

### Lancer les services

```bash
# DÃ©marrer tous les services (API, UI, Monitoring)
docker compose up -d

# VÃ©rifier la santÃ© des services
curl -u f1pa:f1pa http://localhost:8000/health
```

**Services disponibles** :
- ðŸ”¹ **API Documentation** : [http://localhost:8000/docs](http://localhost:8000/docs)
- ðŸ”¹ **Streamlit UI** : [http://localhost:8501](http://localhost:8501)
- ðŸ”¹ **MLflow** : [http://localhost:5000](http://localhost:5000)
- ðŸ”¹ **Grafana** : [http://localhost:3000](http://localhost:3000) (admin/admin)
- ðŸ”¹ **Prometheus** : [http://localhost:9090](http://localhost:9090)

### ExÃ©cuter le pipeline ETL

```bash
# Pipeline complet (Extract â†’ Transform â†’ Load)
python scripts/etl_pipeline.py --years 2023 2024 2025

# Options
python scripts/etl_pipeline.py --years 2024 2025 --skip-extract  # Si donnÃ©es dÃ©jÃ  extraites
python scripts/etl_pipeline.py --verify-only                      # VÃ©rification qualitÃ© uniquement
```

**RÃ©sultat** :
- Dataset ML : `data/processed/dataset_ml_lap_level_2023_2024_2025.csv`
- Base PostgreSQL peuplÃ©e (4 tables, 71k+ laps)

### EntraÃ®ner le modÃ¨le

```bash
# EntraÃ®nement avec GridSearchCV + MLflow tracking
python ml/run_ml_pipeline.py
```

**RÃ©sultats** :
- ModÃ¨le Random Forest (GridSearchCV) : MAE 1.08s, RÂ² 0.79
- Tracking MLflow : [http://localhost:5000](http://localhost:5000)

---

## ðŸ—ï¸ Architecture

```
F1PA/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ extract/         # DonnÃ©es brutes (OpenF1, Wikipedia, Meteostat)
â”‚   â”œâ”€â”€ transform/       # DonnÃ©es enrichies et nettoyÃ©es
â”‚   â””â”€â”€ processed/       # Dataset ML final (71k laps Ã— 31 features)
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract/         # Scripts extraction (API + scraping)
â”‚   â”œâ”€â”€ transform/       # 6 Ã©tapes de transformation
â”‚   â””â”€â”€ load/            # Chargement PostgreSQL
â”‚
â”œâ”€â”€ ml/                  # Pipeline ML (preprocessing, training, inference)
â”œâ”€â”€ api/                 # FastAPI REST (endpoints + auth)
â”œâ”€â”€ streamlit/           # Interface utilisateur
â”œâ”€â”€ monitoring/          # Evidently (drift detection)
â”œâ”€â”€ tests/               # 53 tests (unitaires + intÃ©gration)
â”‚
â”œâ”€â”€ scripts/             # Scripts utilitaires (ETL, monitoring, dÃ©ploiement)
â”œâ”€â”€ .github/workflows/   # CI/CD GitHub Actions
â””â”€â”€ docker-compose.yml   # Services (PostgreSQL, MLflow, Prometheus, Grafana)
```

### Pipeline ETL

**Extract** :
- OpenF1 API : sessions, circuits, laps, drivers
- Wikipedia : coordonnÃ©es gÃ©ographiques circuits
- Meteostat : donnÃ©es mÃ©tÃ©o horaires

**Transform** (6 Ã©tapes) :
1. Filtrage sessions Race
2. Extraction laps via OpenF1
3. Nettoyage outliers (quantiles)
4. Enrichissement contexte (circuit, pilote)
5. Jointure mÃ©tÃ©o horaire
6. Construction dataset ML final

**Load** :
- PostgreSQL 15 (schÃ©ma en Ã©toile)
- 4 tables : `fact_laps`, `dim_drivers`, `dim_circuits`, `dim_sessions`


### ModÃ¨le ML

**Objectif** : PrÃ©dire `lap_duration`

**Features principales** :
- Sport : `st_speed`, `i1_speed`, `i2_speed` (vitesses historiques)
- MÃ©tÃ©o : `temp`, `rhum`, `pres` (tempÃ©rature, humiditÃ©, pression)
- Contexte : `circuit_avg_laptime`, `driver_perf_score`, `lap_progress`

**ModÃ¨le** : Random Forest (GridSearchCV)
- **MAE** : 1.08s (test)
- **RÂ²** : 0.79 (test)
- **MAPE** : 0.90%
- **Features** : 14 features
- **Model size** : 335 MB (production-ready)
- **Tracking** : MLflow (hyperparams, metrics, feature importance)

### Optimisation du modÃ¨le

Le modÃ¨le a Ã©tÃ© optimisÃ© Ã  travers plusieurs itÃ©rations (v0 â†’ v6) :
- **RÃ©duction taille** : 1.5 GB â†’ 335 MB (-78%)
- **AmÃ©lioration performance** : RÂ² 0.77 â†’ 0.79
- **Optimisation features** : Suppression redondance driver_avg_laptime (15 â†’ 14 features)
- **Temps chargement API** : 19s â†’ ~3s

ðŸ“š **Documentation dÃ©taillÃ©e** : [ml/MODEL_OPTIMIZATION.md](ml/MODEL_OPTIMIZATION.md)


### ScalabilitÃ© Big Data

**Architecture actuelle** : PostgreSQL 15 (adaptÃ© pour ~71k laps)

**Scale-up pour volumes > 10M rows** :
- **Apache Spark SQL** : RequÃªtes distribuÃ©es sur clusters Hadoop/HDFS
- **Apache Hive** : Data warehouse SQL sur Big Data avec partitionnement
- **Presto/Trino** : RequÃªtes SQL temps rÃ©el sur data lakes (S3, HDFS)

Le projet est conÃ§u pour faciliter la migration : les requÃªtes SQL PostgreSQL sont compatibles Spark SQL avec adaptations mineures (types de donnÃ©es, fonctions de fenÃªtrage).

---

## ðŸ“Š Monitoring & MLOps

### CI/CD Pipeline

**GitHub Actions** - Workflow automatique sur chaque push :

```
Push â†’ Lint â†’ Tests â†’ Build â†’ Deploy
       â†“      â†“       â†“
    pylint  pytest  docker
           53 tests  images
```

**Workflows** :
- âœ… `.github/workflows/ci.yml` - Lint (pylint), test, build automatique
- âœ… `.github/workflows/release.yml` - Releases versionnÃ©es (tags `v*.*.*`)

**Tests locaux** :
```bash
pylint --rcfile=pyproject.toml api/ ml/ etl/ monitoring/ streamlit/ tests/ scripts/  # Code quality
pytest tests/ -v --cov=. --cov-report=term-missing  # 53 tests avec coverage
docker compose build            # Build images
docker compose up -d            # Lancer services
```

### Monitoring ML

**Prometheus + Grafana** :
- MÃ©triques API : requÃªtes/sec, latence, erreurs
- MÃ©triques modÃ¨le : prÃ©dictions, temps d'infÃ©rence
- Dashboard Grafana : [http://localhost:3000](http://localhost:3000)

**Evidently** - DÃ©tection de drift :
```bash
# GÃ©nÃ©rer rapport de drift
docker exec f1pa_api python scripts/generate_drift_report.py

# Rapport HTML : monitoring/evidently/reports/test_data_drift.html
```

**Alertes** :
- Drift dÃ©tectÃ© sur features (threshold configurable)
- Performance dÃ©gradÃ©e (MAE > seuil)

ðŸ“š **Documentation dÃ©taillÃ©e** : [monitoring/README.md](monitoring/README.md)

---


## ðŸ“– Documentation

**Guides essentiels** :

- ðŸ“˜ [DEVELOPMENT.md](DEVELOPMENT.md) - **Guide complet** : dÃ©veloppement, tests, CI/CD, dÃ©ploiement
- ðŸ¤– [ml/MODEL_OPTIMIZATION.md](ml/MODEL_OPTIMIZATION.md) - Optimisation du modÃ¨le ML (v0 â†’ v6)
- ðŸ“Š [monitoring/MONITORING.md](monitoring/MONITORING.md) - Monitoring ML (Prometheus, Grafana, Evidently)
- ðŸ”§ [scripts/README.md](scripts/README.md) - Scripts utilitaires (ETL, monitoring, dÃ©ploiement)
- ðŸ”’ [RGPD.md](RGPD.md) - ConformitÃ© RGPD

**API Documentation** :
- Swagger UI : [http://localhost:8000/docs](http://localhost:8000/docs)
- Endpoints : `/predict/lap`, `/data/drivers`, `/data/circuits`
- **Authentification** :
  - Dev/DÃ©mo : HTTP Basic Auth (username/password)
  - Production recommandÃ©e : JWT/OAuth2 pour sÃ©curitÃ© renforcÃ©e

---